{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSanr8lG1riS"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"Parking Violation Classifier\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"parking_violation.csv\")\n",
        "\n",
        "# Select relevant features and target variable\n",
        "features = ['Plate Type', 'Vehicle Body Type', 'Vehicle Make', 'Violation Location', 'Registration State', 'Vehicle Year']\n",
        "target = 'Violation Code'\n",
        "\n",
        "# Define the pipeline stages\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "clf = RandomForestClassifier(numTrees=100, seed=42, labelCol=target)\n",
        "\n",
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, clf])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "(training_data, testing_data) = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train the pipeline\n",
        "model = pipeline.fit(training_data)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(testing_data)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=target, predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Predict the violation type for a new parking ticket\n",
        "new_ticket = spark.createDataFrame([(['PAS', 'SUBN', 'ACURA', 14, 'NY', 2018],)], schema=[\"Plate Type\", \"Vehicle Body Type\", \"Vehicle Make\", \"Violation Location\", \"Registration State\", \"Vehicle Year\"])\n",
        "predicted_violation = model.transform(new_ticket).select(\"prediction\").collect()[0][0]\n",
        "print(f\"Predicted violation type: {predicted_violation}\")\n"
      ]
    }
  ]
}